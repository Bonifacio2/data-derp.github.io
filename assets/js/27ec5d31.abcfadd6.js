"use strict";(self.webpackChunkdata_derp=self.webpackChunkdata_derp||[]).push([[4405],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return h}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=p(n),h=r,m=d["".concat(l,".").concat(h)]||d[h]||u[h]||i;return n?a.createElement(m,o(o({ref:t},c),{},{components:n})):a.createElement(m,o({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},8901:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return p},toc:function(){return c},default:function(){return d}});var a=n(3117),r=n(102),i=(n(7294),n(3905)),o=["components"],s={sidebar_position:8},l="Wrangling with Spark",p={unversionedId:"data-transformation/wrangling-with-spark",id:"data-transformation/wrangling-with-spark",title:"Wrangling with Spark",description:"Working with Databricks",source:"@site/docs/data-transformation/wrangling-with-spark.mdx",sourceDirName:"data-transformation",slug:"/data-transformation/wrangling-with-spark",permalink:"/docs/data-transformation/wrangling-with-spark",editUrl:"https://github.com/data-derp/data-derp.github.io/tree/master/docs/docs/data-transformation/wrangling-with-spark.mdx",tags:[],version:"current",lastUpdatedBy:"Kelsey Mok",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Spark on Kubernetes",permalink:"/docs/data-transformation/spark-on-kubernetes"},next:{title:"Quiz",permalink:"/docs/data-transformation/quiz"}},c=[{value:"Working with Databricks",id:"working-with-databricks",children:[],level:2},{value:"What&#39;s Missing from These Notebooks?",id:"whats-missing-from-these-notebooks",children:[],level:2},{value:"Window Functions",id:"window-functions",children:[],level:2},{value:"Python UDFs",id:"python-udfs",children:[{value:"How can I bring in my own custom Python logic?",id:"how-can-i-bring-in-my-own-custom-python-logic",children:[],level:3},{value:"But..how can we be more efficient when switching between the JVM and Python??",id:"buthow-can-we-be-more-efficient-when-switching-between-the-jvm-and-python",children:[],level:3},{value:"Wowww, how do I actually use Pandas UDFs then?",id:"wowww-how-do-i-actually-use-pandas-udfs-then",children:[],level:3}],level:2},{value:"A Deeper Reference",id:"a-deeper-reference",children:[],level:2}],u={toc:c};function d(e){var t=e.components,s=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,a.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"wrangling-with-spark"},"Wrangling with Spark"),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("figure",{class:"video-container"},(0,i.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/r418tWNnAq8",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}))),(0,i.kt)("h2",{id:"working-with-databricks"},"Working with Databricks"),(0,i.kt)("p",null,"We'll walk through some of the basic transformation methods using notebooks"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("a",{parentName:"li",href:"https://community.cloud.databricks.com/login.html"},"Create a Commmunity Edition Account")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("a",{parentName:"li",href:"https://github.com/data-derp/small-exercises/raw/master/databricks-spark-training.dbc"},"Download Exercises")),(0,i.kt)("li",{parentName:"ol"},"Upload the .dbc file to Databricks\n",(0,i.kt)("img",{alt:"databricks-import.png",src:n(5953).Z}))),(0,i.kt)("h2",{id:"whats-missing-from-these-notebooks"},"What's Missing from These Notebooks?"),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("p",null,(0,i.kt)("img",{alt:"cool-stuff-missing.png",src:n(4020).Z}))),(0,i.kt)("p",null,"Short Answer:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The really cool stuff"),(0,i.kt)("li",{parentName:"ul"},"Window Functions"),(0,i.kt)("li",{parentName:"ul"},"Pandas UDFs (Vectorised UDFs)")),(0,i.kt)("h2",{id:"window-functions"},"Window Functions"),(0,i.kt)("p",null,"Just make sure you understand everything about window function semantics"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"partitionBy",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"similar to groupBy (but doesn\u2019t reduce/aggregate information down to a single row)"))),(0,i.kt)("li",{parentName:"ul"},"orderBy",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Just FYI, you can orderBy(F.col(\u201cmyColumn\u201d).desc()) for descending order."))),(0,i.kt)("li",{parentName:"ul"},"rowsBetween",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"You should look up the default arguments for different window functions (e.g. lag, lead, first, last, max, min, row_number)"))),(0,i.kt)("li",{parentName:"ul"},"rangeBetween\nCan you explain the difference between rowsBetween and rangeBetween?")),(0,i.kt)("p",null,"These are all also concepts in SQL."),(0,i.kt)("h2",{id:"python-udfs"},"Python UDFs"),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("p",null,(0,i.kt)("img",{alt:"python-udfs.png",src:n(2279).Z}))),(0,i.kt)("h3",{id:"how-can-i-bring-in-my-own-custom-python-logic"},"How can I bring in my own custom Python logic?"),(0,i.kt)("p",null,"(needs other libraries, not available as pyspark built-in functions)"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Basic Answer:")," ",(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html"},"Python UDFs")),(0,i.kt)("p",null,"How does this work? "),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"JVM serializes data and sends it to the Python process "),(0,i.kt)("li",{parentName:"ul"},"Python process deserializes, then serializes it back to the JVM "),(0,i.kt)("li",{parentName:"ul"},"JVM deserializes the data for running next operations/steps")),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("p",null,(0,i.kt)("img",{alt:"python-udf-execution.png",src:n(4579).Z}))),(0,i.kt)("h3",{id:"buthow-can-we-be-more-efficient-when-switching-between-the-jvm-and-python"},"But..how can we be more efficient when switching between the JVM and Python??"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Basic Answer:")," Vectorization"),(0,i.kt)("p",null,"How does this work? (the Apache Arrow project is basically dedicated to this!)"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Batches/chunks of a single/multiple column(s) are serialized compactly/efficiently then sent to the Python process"),(0,i.kt)("li",{parentName:"ul"},"Which Python library is really good at vectorized operations on data again?",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Pandas! uses NumPy (written in C) under the hood"))),(0,i.kt)("li",{parentName:"ul"},"Chunks of data are serialized then finally sent back to the JVM")),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"A pandas user-defined function (UDF)\u2014also known as vectorized UDF\u2014is a user-defined function that uses Apache Arrow to transfer data and pandas to work with the data. pandas UDFs allow vectorized operations that can increase performance up to 100x compared to row-at-a-time Python UDFs. (",(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html#pandas-user-defined-functions"},"Reference"),")")),(0,i.kt)("div",{style:{textAlign:"center"}},(0,i.kt)("p",null,(0,i.kt)("img",{alt:"apply-in-pandas.png",src:n(6601).Z}))),(0,i.kt)("p",null,"This even allows you to run custom logic per each group of data in a distributed manner:"),(0,i.kt)("p",null,"Pandas DataFrame ",(0,i.kt)("strong",{parentName:"p"},"IN"),"\nPandas DataFrame ",(0,i.kt)("strong",{parentName:"p"},"OUT"),"\nThis is ",(0,i.kt)("strong",{parentName:"p"},"massive"),"."),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/pandas-function-apis.html"},"Reference Docs")),(0,i.kt)("h3",{id:"wowww-how-do-i-actually-use-pandas-udfs-then"},"Wowww, how do I actually use Pandas UDFs then?"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Basic Answer:")," Learn the different types of ",(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html"},"Pandas UDFs")," AND ",(0,i.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/pandas-function-apis.html"},"Pandas Functions APIs")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Example blog post (",(0,i.kt)("a",{parentName:"li",href:"https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html"},"potentially outdated"),")"),(0,i.kt)("li",{parentName:"ul"},"Series to Series (these can often directly replace your Python UDFs)"),(0,i.kt)("li",{parentName:"ul"},"Grouped Map (Pandas Functions APIs)",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"This is ",(0,i.kt)("strong",{parentName:"li"},"THE holy grail"),", you can parallelize data processing by treating each \u201cgroup\u201d as an independent Pandas DataFrame")))),(0,i.kt)("h2",{id:"a-deeper-reference"},"A Deeper Reference"),(0,i.kt)("p",null,"Check out O'Reilly's ",(0,i.kt)("a",{parentName:"p",href:"https://www.oreilly.com/library/view/learning-spark/9781449359034/"},'"Learning Spark" book')))}d.isMDXComponent=!0},6601:function(e,t,n){t.Z=n.p+"assets/images/apply-in-pandas-d69add633d5ca73e8e6cb0442685790d.png"},4020:function(e,t,n){t.Z=n.p+"assets/images/cool-stuff-missing-0ee10a3baedda8a05b77b46c3c1c2b5e.png"},5953:function(e,t,n){t.Z=n.p+"assets/images/databricks-import-66829f40b9d3975a50b37dd6da4c7cce.png"},4579:function(e,t,n){t.Z=n.p+"assets/images/python-udf-execution-f2d17b957a120678fb004c7574df7a3d.png"},2279:function(e,t,n){t.Z=n.p+"assets/images/python-udfs-b7abfb9be3f6289696de0eb5a55a3939.png"}}]);