"use strict";(self.webpackChunkdata_derp=self.webpackChunkdata_derp||[]).push([[3008],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=c(n),m=r,f=u["".concat(s,".").concat(m)]||u[m]||p[m]||o;return n?a.createElement(f,i(i({ref:t},d),{},{components:n})):a.createElement(f,i({ref:t},d))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<o;c++)i[c]=n[c];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},746:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return c},toc:function(){return d},default:function(){return u}});var a=n(3117),r=n(102),o=(n(7294),n(3905)),i=["components"],l={sidebar_position:8},s="Advanced Wrangling",c={unversionedId:"data-transformation/advanced-wrangling",id:"data-transformation/advanced-wrangling",title:"Advanced Wrangling",description:"What's missing?",source:"@site/docs/data-transformation/advanced-wrangling.mdx",sourceDirName:"data-transformation",slug:"/data-transformation/advanced-wrangling",permalink:"/docs/data-transformation/advanced-wrangling",editUrl:"https://github.com/data-derp/data-derp.github.io/tree/master/docs/docs/data-transformation/advanced-wrangling.mdx",tags:[],version:"current",lastUpdatedBy:"Kelsey Mok",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Spark Workflow and Partitioning",permalink:"/docs/data-transformation/spark-workflow-and-partitioning"},next:{title:"Exercise: Core Logic",permalink:"/docs/data-transformation/exercise-core-logic"}},d=[{value:"What&#39;s missing?",id:"whats-missing",children:[],level:2},{value:"Window Functions",id:"window-functions",children:[{value:"Try it yourself",id:"try-it-yourself",children:[],level:3}],level:2},{value:"Python UDFs",id:"python-udfs",children:[{value:"How can I bring in my own custom Python logic?",id:"how-can-i-bring-in-my-own-custom-python-logic",children:[],level:3},{value:"But..how can we be more efficient when switching between the JVM and Python??",id:"buthow-can-we-be-more-efficient-when-switching-between-the-jvm-and-python",children:[],level:3},{value:"Wowww, how do I actually use Pandas UDFs then?",id:"wowww-how-do-i-actually-use-pandas-udfs-then",children:[],level:3},{value:"Try it yourself (optional)",id:"try-it-yourself-optional",children:[],level:3}],level:2},{value:"A Deeper Reference",id:"a-deeper-reference",children:[],level:2}],p={toc:d};function u(e){var t=e.components,l=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,a.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"advanced-wrangling"},"Advanced Wrangling"),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("figure",{class:"video-container"},(0,o.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/r418tWNnAq8",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}))),(0,o.kt)("h2",{id:"whats-missing"},"What's missing?"),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("p",null,(0,o.kt)("img",{alt:"cool-stuff-missing.png",src:n(4020).Z}))),(0,o.kt)("p",null,"Short Answer:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"The really cool stuff"),(0,o.kt)("li",{parentName:"ul"},"Window Functions"),(0,o.kt)("li",{parentName:"ul"},"Pandas UDFs (Vectorised UDFs)")),(0,o.kt)("h2",{id:"window-functions"},"Window Functions"),(0,o.kt)("p",null,"It is important to make sure you understand everything about window function semantics"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"partitionBy",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"similar to groupBy (but doesn\u2019t reduce/aggregate information down to a single row)"))),(0,o.kt)("li",{parentName:"ul"},"orderBy",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Just FYI, you can orderBy(F.col(\u201cmyColumn\u201d).desc()) for descending order."))),(0,o.kt)("li",{parentName:"ul"},"rowsBetween",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"You should look up the default arguments for different window functions (e.g. lag, lead, first, last, max, min, row_number)"))),(0,o.kt)("li",{parentName:"ul"},"rangeBetween\nCan you explain the difference between rowsBetween and rangeBetween?")),(0,o.kt)("p",null,"These are ",(0,o.kt)("a",{parentName:"p",href:"https://towardsdatascience.com/a-guide-to-advanced-sql-window-functions-f63f2642cbf9"},"all also concepts in SQL and not special to Spark"),"."),(0,o.kt)("h3",{id:"try-it-yourself"},"Try it yourself"),(0,o.kt)("p",null,"Follow the instructions here for the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/data-derp/small-exercises/tree/master/window-functions"},"Windows Walkthrough")),(0,o.kt)("h2",{id:"python-udfs"},"Python UDFs"),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("p",null,(0,o.kt)("img",{alt:"python-udfs.png",src:n(2279).Z}))),(0,o.kt)("h3",{id:"how-can-i-bring-in-my-own-custom-python-logic"},"How can I bring in my own custom Python logic?"),(0,o.kt)("p",null,"(needs other libraries, not available as pyspark built-in functions)"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Basic Answer:")," ",(0,o.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html"},"Python UDFs")),(0,o.kt)("p",null,"How does this work?"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"JVM serializes data and sends it to the Python process"),(0,o.kt)("li",{parentName:"ul"},"Python process deserializes, then serializes it back to the JVM"),(0,o.kt)("li",{parentName:"ul"},"JVM deserializes the data for running next operations/steps")),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("p",null,(0,o.kt)("img",{alt:"python-udf-execution.png",src:n(4579).Z}))),(0,o.kt)("h3",{id:"buthow-can-we-be-more-efficient-when-switching-between-the-jvm-and-python"},"But..how can we be more efficient when switching between the JVM and Python??"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Basic Answer:")," Vectorization"),(0,o.kt)("p",null,"How does this work? (the Apache Arrow project is basically dedicated to this!)"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Batches/chunks of a single/multiple column(s) are serialized compactly/efficiently then sent to the Python process"),(0,o.kt)("li",{parentName:"ul"},"Which Python library is really good at vectorized operations on data again?",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Pandas! uses NumPy (written in C) under the hood"))),(0,o.kt)("li",{parentName:"ul"},"Chunks of data are serialized then finally sent back to the JVM")),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"A pandas user-defined function (UDF)\u2014also known as vectorized UDF\u2014is a user-defined function that uses Apache Arrow to transfer data and pandas to work with the data. pandas UDFs allow vectorized operations that can increase performance up to 100x compared to row-at-a-time Python UDFs. (",(0,o.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html#pandas-user-defined-functions"},"Reference"),")")),(0,o.kt)("div",{style:{textAlign:"center"}},(0,o.kt)("p",null,(0,o.kt)("img",{alt:"apply-in-pandas.png",src:n(6601).Z}))),(0,o.kt)("p",null,"This even allows you to run custom logic per each group of data in a distributed manner:"),(0,o.kt)("p",null,"Pandas DataFrame ",(0,o.kt)("strong",{parentName:"p"},"IN"),"\nPandas DataFrame ",(0,o.kt)("strong",{parentName:"p"},"OUT"),"\nThis is ",(0,o.kt)("strong",{parentName:"p"},"massive"),"."),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/pandas-function-apis.html"},"Reference Docs")),(0,o.kt)("h3",{id:"wowww-how-do-i-actually-use-pandas-udfs-then"},"Wowww, how do I actually use Pandas UDFs then?"),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Basic Answer:")," Learn the different types of ",(0,o.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/udf-python-pandas.html"},"Pandas UDFs")," AND ",(0,o.kt)("a",{parentName:"p",href:"https://docs.databricks.com/spark/latest/spark-sql/pandas-function-apis.html"},"Pandas Functions APIs")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Example blog post (",(0,o.kt)("a",{parentName:"li",href:"https://databricks.com/blog/2017/10/30/introducing-vectorized-udfs-for-pyspark.html"},"potentially outdated"),")"),(0,o.kt)("li",{parentName:"ul"},"Series to Series (these can often directly replace your Python UDFs)"),(0,o.kt)("li",{parentName:"ul"},"Grouped Map (Pandas Functions APIs)",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"This is ",(0,o.kt)("strong",{parentName:"li"},"THE holy grail"),", you can parallelize data processing by treating each \u201cgroup\u201d as an independent Pandas DataFrame"),(0,o.kt)("li",{parentName:"ul"})))),(0,o.kt)("h3",{id:"try-it-yourself-optional"},"Try it yourself (optional)"),(0,o.kt)("p",null,"Import the following Pandas UDF benchmark notebook into Databricks using the URL method:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1281142885375883/2174302049319883/7729323681064935/latest.html?_gl=1*1dt6rri*_gcl_aw*R0NMLjE2NTgwNTYzNjguRUFJYUlRb2JDaE1JME1mR24tWF8tQUlWVHRrUkNCMHdqd05IRUFFWUFTQUFFZ0pJM3ZEX0J3RQ..&_ga=2.69934608.18112261.1660751261-1602603096.1651760939&_gac=1.262850872.1658056369.EAIaIQobChMI0MfGn-X_-AIVTtkRCB0wjwNHEAEYASAAEgJI3vD_BwE\n")),(0,o.kt)("h2",{id:"a-deeper-reference"},"A Deeper Reference"),(0,o.kt)("p",null,"Check out O'Reilly's ",(0,o.kt)("a",{parentName:"p",href:"https://www.oreilly.com/library/view/learning-spark/9781449359034/"},'"Learning Spark" book')))}u.isMDXComponent=!0},6601:function(e,t,n){t.Z=n.p+"assets/images/apply-in-pandas-d69add633d5ca73e8e6cb0442685790d.png"},4020:function(e,t,n){t.Z=n.p+"assets/images/cool-stuff-missing-0ee10a3baedda8a05b77b46c3c1c2b5e.png"},4579:function(e,t,n){t.Z=n.p+"assets/images/python-udf-execution-f2d17b957a120678fb004c7574df7a3d.png"},2279:function(e,t,n){t.Z=n.p+"assets/images/python-udfs-b7abfb9be3f6289696de0eb5a55a3939.png"}}]);